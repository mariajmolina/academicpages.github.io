---
title: 'Delivered Core Science Keynote at AMS annual meeting'
date: 2021-01-15
permalink: /posts/2021/01/blog-post-1/
tags:
  - presentation
  - outreach
  - science
---

I delivered my first core science keynote at the 101st annual meeting of the American Meteorological Society, titled **"How Python and Machine Learning Enable Advances in Earth Science."**

Virtual conference
======
The 101st AMS annual meeting was held virtually, due to the ongoing COVID-19 pandemic. The conference featured numerous pre-recorded presentations, lightning summary talks, and live panels and poster sessions. My core science keynote was delivered live and I had the honor of talking about how python and machine learning are transforming how we do Earth science. Below are some of the key takeaways.

Brief history of Python
------
Python’s history dates back to the late-1980s, developed by Guido van Rossum as a hobby project that started over a winter holiday season. It was designed to be an interpreted programming language with an emphasis on code readability. Python was first released in 1991 as version 0.9, and it was named after the show Monty Python’s Flying Circus, not the snake. Python at that point had capabilities to handle classes with inheritance, exception handling and functions. In 1994, Python version 1.0 was released with functional programming tools, like lambda, filter, and reduce. In the year 2000, Python version 2.0 was released, and added new features such as list comprehensions and the cycle--- detecting garbage collection system -- which is a process by which python periodically frees memory no longer in use. In 2008, Python version 3.0 was released, which was designed to correct some flaws in the language and this version also lost backward compatibility with earlier versions of Python. As of about a year ago, Python version 2 is no longer supported. 

![pythonhistory](https://github.com/mariajmolina/mariajmolina.github.io/blob/master/images/AMS2021_1.pdf?raw=true)

If python has been around for about 30 years now, why does it seem to have become widely adopted in just the last few years? There are several key reasons for this. Because of its code readability and easy interpretability, Python is an accessible high level language and is used across a broad range of fields beyond the earth sciences. As a result, it has gained a large user base of active and supportive contributors, including software engineers, data analysts, network engineers, scientists, and mathematicians. Having been around for 30 years also means that the language has reached a mature phase, with a large ecosystem of packages and many tutorials and examples freely available to help users accomplish their goals. Python has also been used on many large scale projects with success, including at companies like Google, which has led to organizations investing in the language and learning materials for their workforces. So while lots of programming languages have been around for a long time, these reasons can partly explain the growth of python’s popularity.


Brief history of Machine Learning
------
Machine learning has a long and rich history, that extends further back than python’s history. The 1950s and 1980s saw excitement in the field, including the development of key terms and algorithms, such as the perceptron algorithm which was the precursor to modern neural networks, and the development of the backpropagation algorithm, allowing for multi-layered models and improved parameter optimization. These advances also had periods of disappointment and reduced funding, two time periods known as AI winters, due in part to skepticism of the field’s progress and limited technology. More recently, further development of deep convolutional neural networks occurred. The ImageNet database was worked on for several years in the 2000s, which was a groundbreaking dataset consisting of over 14 million high quality labeled images for over 22-thousand categories, ideal for training models in a supervised learning framework. The objective of this dataSET was to benchmark model development and to overcome challenges with model overfitting. This started the ImageNet Large-Scale Visual Recognition Challenge, and in 2012, a large drop in error was recorded by the winning model, which was a convolutional neural network. Its high performance was attributed to its depth.


Python and Machine Learning in my postdoc research
------
I will now illustrate how python and machine learning can be used with a relatively straightforward research problem. In this study, we have many thunderstorms that we extracted from a convection permitting climate simulation and then we trained a convolutional neural network to classify these storms into two categories. The machine learning workflow in a supervised learning framework can be generally summarized into three steps, step one being data preprocessing in preparation for model training, step two involving the training of the machine learning model, which will be a convolutional neural network, and step three involving the evaluation of the model using unseen test data. During step three, machine learning interpretability can also be conducted to help explain the reasons for model skill, and we will illustrate this using saliency maps. 

This high-level overview provided an example of how to navigate the various stages of a machine learning project, from start to finish in python. Navigating between python libraries is relatively efficient and provides smooth transitions throughout the full workflow of a project, which makes it easy for scientists with little-to-no software development training, like myself, to be able to focus more on the science. Here we saw that by combining dask and xarray, computations could be conducted on large, multi-dimensional datasets through parallel computing. Keras can be used to build and train convolutional neural networks in just a few lines of code. And finally, the large number of scientific computing libraries, ranging from numpy to pandas, can be leverage to analyze the skill of our trained machine learning models and explain our results.

To close, I’d like to leave you with some recommended materials for getting started or refining skills in python and machine learning. On github, scientists at NCAR have made available recent tutorials for python and machine learning. The books listed here were also useful to me. However, the most helpful thing for me has been to apply these techniques to real research problems! If you have any questions, please feel free to contact me at the email listed on the bottom of this slide. Thank you so much for your attention. 
